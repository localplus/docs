# ğŸ’¾ **Data Architecture**
## *LOCAL-PLUS Database, Kafka, Cache & Queues*

---

> **Retour vers** : [Architecture Overview](../EntrepriseArchitecture.md)

---

# ğŸ“‹ **Table of Contents**

1. [Aiven Configuration](#aiven-configuration)
2. [Database Strategy](#database-strategy)
3. [Schema Ownership](#schema-ownership)
4. [Kafka Topics](#kafka-topics)
5. [Kafka Monitoring](#kafka-monitoring)
6. [Cache Architecture (Valkey)](#cache-architecture-valkey)
7. [Queueing & Background Jobs](#queueing--background-jobs)

---

# ğŸ—„ï¸ **Aiven Configuration**

## Services Overview

| Service | Plan | Config | CoÃ»t estimÃ© |
|---------|------|--------|-------------|
| **PostgreSQL** | Business-4 | Primary + Read Replica, 100GB | ~300â‚¬/mois |
| **Kafka** | Business-4 | 3 brokers, 100GB retention | ~400â‚¬/mois |
| **Valkey (Redis)** | Business-4 | 2 nodes, 10GB, HA | ~150â‚¬/mois |

**CoÃ»t total Aiven estimÃ© : ~850â‚¬/mois**

---

# ğŸ˜ **Database Strategy**

## Configuration

| Aspect | Choix | Rationale |
|--------|-------|-----------|
| **Replication** | Aiven managed (async) | RPO 1h acceptable |
| **Backup** | Aiven automated hourly | RPO 1h |
| **Failover** | Aiven automated | RTO < 15min |
| **Connection** | VPC Peering (private) | PCI-DSS, no public internet |
| **Pooling** | PgBouncer (Aiven built-in) | Connection efficiency |

## Connection Best Practices

| ParamÃ¨tre | Valeur recommandÃ©e | Rationale |
|-----------|-------------------|-----------|
| **pool_size** | 20 | Nombre de connexions par pod |
| **max_overflow** | 10 | Connexions supplÃ©mentaires en pic |
| **pool_timeout** | 30s | Attente max pour une connexion |
| **pool_recycle** | 1800s | Recycler connexions toutes les 30min |
| **ssl** | require | Obligatoire pour PCI-DSS |

---

# ğŸ“Š **Schema Ownership**

| Table | Owner Service | Access pattern |
|-------|---------------|----------------|
| `transactions` | svc-ledger | CRUD |
| `ledger_entries` | svc-ledger | CRUD |
| `wallets` | svc-wallet | CRUD |
| `balance_snapshots` | svc-wallet | CRUD |
| `merchants` | svc-merchant | CRUD |
| `giftcards` | svc-giftcard | CRUD |

**RÃ¨gle d'or : 1 table = 1 owner. Cross-service = gRPC ou Events, jamais JOIN.**

---

# ğŸ“¨ **Kafka Topics**

## Topic Configuration

| Topic | Producer | Consumers | Retention |
|-------|----------|-----------|-----------|
| `ledger.transactions.v1` | svc-ledger (Outbox) | svc-notification, svc-analytics | 7 jours |
| `wallet.balance-updated.v1` | svc-wallet | svc-analytics | 7 jours |
| `merchant.onboarded.v1` | svc-merchant | svc-notification | 7 jours |

## Outbox Pattern avec Debezium

> **Implementation** : On utilise **Debezium** avec **PostgreSQL Logical Replication** (publication + replication slot), pas le polling.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    OUTBOX PATTERN (Debezium CDC)                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  1. Application writes to DB + Outbox table in same transaction             â”‚
â”‚  2. Debezium reads WAL via replication slot                                 â”‚
â”‚  3. Events published to Kafka                                               â”‚
â”‚  4. Consumers process events                                                â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚ svc-*   â”‚â”€â”€â”€â–ºâ”‚ PostgreSQL  â”‚â”€â”€â”€â–ºâ”‚ Debezium â”‚â”€â”€â”€â–ºâ”‚   Kafka     â”‚         â”‚
â”‚  â”‚         â”‚    â”‚ (WAL/Slot)  â”‚    â”‚  (CDC)   â”‚    â”‚             â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                                           â”‚                 â”‚
â”‚                 Publication + Replication Slot            â–¼                 â”‚
â”‚                                                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚                                                  â”‚   Consumers     â”‚        â”‚
â”‚                                                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Debezium Configuration

| Composant | Description |
|-----------|-------------|
| **Publication** | `CREATE PUBLICATION outbox_pub FOR TABLE outbox;` |
| **Replication Slot** | CrÃ©Ã© automatiquement par Debezium |
| **Connector** | Debezium PostgreSQL Connector |
| **Output** | Kafka topic par table (ou SMT pour routing) |

## Outbox Table Structure

| Colonne | Type | Description |
|---------|------|-------------|
| `id` | UUID | Primary key |
| `aggregate_type` | VARCHAR(255) | Type d'entitÃ© (Transaction, Wallet...) |
| `aggregate_id` | VARCHAR(255) | ID de l'entitÃ© |
| `event_type` | VARCHAR(255) | Type d'Ã©vÃ©nement |
| `payload` | JSONB | DonnÃ©es de l'Ã©vÃ©nement |
| `created_at` | TIMESTAMPTZ | Timestamp crÃ©ation |

---

# ğŸ“Š **Kafka Monitoring**

## MÃ©triques Essentielles

| MÃ©trique | Description | Seuil Alerte | SÃ©vÃ©ritÃ© |
|----------|-------------|--------------|----------|
| **Consumer Lag** | Messages non traitÃ©s | > 1000 | P2 |
| **Partition Lag** | Lag par partition | > 500 | P3 |
| **Under-replicated Partitions** | Partitions sans rÃ©plicas | > 0 | P1 |
| **Active Controller Count** | Controllers actifs | â‰  1 | P1 |
| **Offline Partitions** | Partitions inaccessibles | > 0 | P1 |
| **Bytes In/Out Rate** | DÃ©bit Kafka | Anomalie > 50% | P3 |
| **Request Latency P99** | Latence requÃªtes | > 100ms | P2 |
| **ISR Shrink Rate** | RÃ©duction In-Sync Replicas | > 0/min sustained | P2 |

## Consumer Lag Monitoring

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         CONSUMER LAG                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  Producer Offset:     1000  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º               â”‚
â”‚  Consumer Offset:      800  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º                         â”‚
â”‚                              â”‚â—„â”€â”€â”€â”€â”€ LAG = 200 â”€â”€â”€â”€â”€â–ºâ”‚                      â”‚
â”‚                                                                              â”‚
â”‚  LAG = Producer Offset - Consumer Offset                                    â”‚
â”‚                                                                              â”‚
â”‚  Causes de Lag Ã©levÃ©:                                                       â”‚
â”‚  â€¢ Consumer lent (processing time)                                          â”‚
â”‚  â€¢ Consumer crashÃ©                                                          â”‚
â”‚  â€¢ Pic de trafic                                                            â”‚
â”‚  â€¢ ProblÃ¨me de partition rebalancing                                        â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Dashboard Kafka RecommandÃ©

| Panel | MÃ©trique | Type |
|-------|----------|------|
| **Total Consumer Lag** | `kafka_consumergroup_lag` | Gauge |
| **Lag par Consumer Group** | `kafka_consumergroup_lag` by group | Gauge |
| **Messages In/sec** | `kafka_server_brokertopicmetrics_messagesin_total` | Counter â†’ Rate |
| **Bytes In/Out** | `kafka_server_brokertopicmetrics_bytesin_total` | Counter â†’ Rate |
| **Request Latency** | `kafka_network_requestmetrics_requestqueuetimems` | Histogram |
| **Partition Count** | `kafka_server_replicamanager_partitioncount` | Gauge |
| **Under-replicated** | `kafka_server_replicamanager_underreplicatedpartitions` | Gauge |

---

# ğŸš€ **Cache Architecture (Valkey)**

## Stack Cache

| Composant | Outil | HÃ©bergement | CoÃ»t estimÃ© |
|-----------|-------|-------------|-------------|
| **Cache primaire** | Valkey (Redis-compatible) | Aiven for Caching | ~150â‚¬/mois |
| **Cache local (L1)** | Python `cachetools` / Go `bigcache` | In-memory | 0â‚¬ |

> **Note :** Valkey est le fork open-source de Redis, maintenu par la Linux Foundation. Aiven supporte Valkey nativement.

## Cache Topology

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         MULTI-LAYER CACHE                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ L1 â€” LOCAL CACHE (per pod)                                          â”‚    â”‚
â”‚  â”‚ â€¢ TTL: 30s - 5min                                                   â”‚    â”‚
â”‚  â”‚ â€¢ Size: 100MB max per pod                                           â”‚    â”‚
â”‚  â”‚ â€¢ Use case: Hot data, config, user sessions                         â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                  â”‚ Cache miss                               â”‚
â”‚                                  â–¼                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ L2 â€” DISTRIBUTED CACHE (Valkey cluster)                             â”‚    â”‚
â”‚  â”‚ â€¢ TTL: 5min - 24h                                                   â”‚    â”‚
â”‚  â”‚ â€¢ Size: 10GB                                                        â”‚    â”‚
â”‚  â”‚ â€¢ Use case: Shared state, rate limits, session store                â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                  â”‚ Cache miss                               â”‚
â”‚                                  â–¼                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ L3 â€” DATABASE (PostgreSQL)                                          â”‚    â”‚
â”‚  â”‚ â€¢ Source of truth                                                   â”‚    â”‚
â”‚  â”‚ â€¢ Write-through pour updates                                        â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Cache Strategies par Use Case

| Use Case | Strategy | TTL | Invalidation |
|----------|----------|-----|--------------|
| **Wallet Balance** | Cache-aside (read) | 30s | Event-driven (Kafka) |
| **Merchant Config** | Read-through | 5min | TTL + Manual |
| **Rate Limiting** | Write-through | Sliding window | Auto-expire |
| **Session Data** | Write-through | 24h | Explicit logout |
| **Gift Card Catalog** | Cache-aside | 15min | Event-driven |
| **Feature Flags** | Read-through | 1min | Config push |

## Cache Patterns

### Cache-Aside Pattern

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         CACHE-ASIDE PATTERN                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  1. Application checks cache                                                 â”‚
â”‚  2. If HIT â†’ return cached data                                             â”‚
â”‚  3. If MISS â†’ query database                                                â”‚
â”‚  4. Store result in cache with TTL                                          â”‚
â”‚  5. Return data to caller                                                   â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    GET     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                         â”‚
â”‚  â”‚   App   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  Cache  â”‚                                         â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                                         â”‚
â”‚       â”‚                      â”‚ MISS                                         â”‚
â”‚       â”‚    SELECT            â–¼                                              â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                        â”‚
â”‚                          â”‚   DB    â”‚                                        â”‚
â”‚                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                        â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Write-Through Pattern

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         WRITE-THROUGH PATTERN                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  1. Application writes to cache AND database atomically                     â”‚
â”‚  2. Cache is always consistent with database                                â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   SET+TTL   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                        â”‚
â”‚  â”‚   App   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  Cache  â”‚                                        â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                        â”‚
â”‚       â”‚                                                                      â”‚
â”‚       â”‚   INSERT/UPDATE                                                      â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                        â”‚
â”‚                          â”‚   DB    â”‚                                        â”‚
â”‚                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                        â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Cache Invalidation Strategy

| Trigger | MÃ©thode | Use Case |
|---------|---------|----------|
| **TTL Expiry** | Automatic | Default pour toutes les clÃ©s |
| **Event-driven** | Kafka consumer | Wallet balance aprÃ¨s transaction |
| **Explicit Delete** | API call | Admin actions, config updates |
| **Pub/Sub** | Valkey PUBLISH | Real-time invalidation cross-pods |

## Cache Key Naming Convention

```
{service}:{entity}:{id}:{version}

Exemples:
  wallet:balance:user_123:v1
  merchant:config:merchant_456:v1
  giftcard:catalog:category_active:v1
  ratelimit:api:user_123:minute
  session:auth:session_abc123
```

## Cache Metrics & Monitoring

| Metric | Seuil alerte | Action |
|--------|--------------|--------|
| **Hit Rate** | < 80% | Revoir TTL, prÃ©chargement |
| **Latency P99** | > 10ms | Check network, cluster size |
| **Memory Usage** | > 80% | Eviction analysis, scale up |
| **Evictions/sec** | > 100 | Augmenter cache size |
| **Connection Errors** | > 0 | Check connectivity, pooling |

---

# ğŸ“‹ **Queueing & Background Jobs**

## Architecture Overview

> **Clarification** : La Task Queue est **interne** aux services, pas en frontal comme RabbitMQ.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TASK QUEUE vs MESSAGE BROKER (RabbitMQ)                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  âŒ Pattern RabbitMQ (frontal) - PAS ce qu'on fait:                         â”‚
â”‚                                                                              â”‚
â”‚     Client â†’ RabbitMQ â†’ Worker â†’ Response to Client (synchrone)            â”‚
â”‚                                                                              â”‚
â”‚  âœ… Notre pattern (Task Queue interne):                                     â”‚
â”‚                                                                              â”‚
â”‚     Client â†’ API (svc-*) â†’ Response immÃ©diate (< 200ms)                    â”‚
â”‚                    â”‚                                                        â”‚
â”‚                    â””â”€â”€â–º enqueue task â†’ Valkey â†’ Worker (async, background)  â”‚
â”‚                                                                              â”‚
â”‚  DiffÃ©rence clÃ©:                                                            â”‚
â”‚  â€¢ L'API rÃ©pond IMMÃ‰DIATEMENT au client                                     â”‚
â”‚  â€¢ Le worker traite en BACKGROUND (fire-and-forget ou avec callback)       â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Queueing Tiers

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         QUEUEING ARCHITECTURE                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ TIER 1 â€” EVENT STREAMING (Kafka)                                    â”‚    â”‚
â”‚  â”‚ â€¢ Use case: Event-driven architecture, CDC, audit logs              â”‚    â”‚
â”‚  â”‚ â€¢ Pattern: Pub/Sub, Event Sourcing                                  â”‚    â”‚
â”‚  â”‚ â€¢ Ordering: Per-partition guaranteed                                â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ TIER 2 â€” TASK QUEUE (Valkey + Dramatiq)                             â”‚    â”‚
â”‚  â”‚ â€¢ Use case: Background jobs, async processing                       â”‚    â”‚
â”‚  â”‚ â€¢ Pattern: Producer/Consumer, Work Queue                            â”‚    â”‚
â”‚  â”‚ â€¢ Features: Retries, priorities, scheduling                         â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ TIER 3 â€” SCHEDULED JOBS (Kubernetes CronJobs)                       â”‚    â”‚
â”‚  â”‚ â€¢ Use case: Batch processing, reports, cleanup                      â”‚    â”‚
â”‚  â”‚ â€¢ Pattern: Time-triggered execution                                 â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Kafka vs Task Queue â€” Quand utiliser quoi ?

| CritÃ¨re | Kafka | Task Queue (Valkey) |
|---------|-------|---------------------|
| **Message Ordering** | âœ… Per-partition | âŒ Best effort |
| **Message Replay** | âœ… Retention-based | âŒ Non |
| **Priority Queues** | âŒ Non natif | âœ… Oui |
| **Delayed Messages** | âŒ Non natif | âœ… Oui |
| **Dead Letter Queue** | âœ… Configurable | âœ… IntÃ©grÃ© |
| **Exactly-once** | âœ… Avec idempotency | âŒ At-least-once |
| **Use Case** | Events entre services | Jobs internes async |

## Task Queue Stack

| Composant | Outil | RÃ´le |
|-----------|-------|------|
| **Task Framework** | Dramatiq (Python) / Asynq (Go) | Task definition, execution |
| **Broker** | Valkey (Redis-compatible) | Message storage, routing |
| **Result Backend** | Valkey | Task results, status |
| **Scheduler** | APScheduler / Dramatiq-crontab | Periodic tasks |
| **Monitoring** | Dramatiq Dashboard / Prometheus | Task metrics |

## Task Processing Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         TASK PROCESSING FLOW                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚   Producer                    Broker                    Workers              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ svc-*   â”‚â”€â”€â”€â”€ enqueue â”€â”€â–ºâ”‚ Valkey  â”‚â—„â”€â”€ poll â”€â”€â”€â”€â”€â”‚ Worker  â”‚            â”‚
â”‚  â”‚ API     â”‚               â”‚         â”‚               â”‚ Pods    â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚ Queues: â”‚               â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜            â”‚
â”‚       â”‚                    â”‚ â€¢ high  â”‚                    â”‚                 â”‚
â”‚       â”‚ Response           â”‚ â€¢ defaultâ”‚                   â”‚ execute         â”‚
â”‚       â”‚ immÃ©diate          â”‚ â€¢ low   â”‚                    â–¼                 â”‚
â”‚       â–¼                    â”‚ â€¢ dlq   â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚   Client                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚  Task   â”‚             â”‚
â”‚   (n'attend pas)                                    â”‚ Handler â”‚             â”‚
â”‚                                                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Queue Definitions

| Queue | Priority | Workers | Use Cases |
|-------|----------|---------|-----------|
| **critical** | P0 | 5 | Transaction rollbacks, fraud alerts |
| **high** | P1 | 10 | Email confirmations, balance updates |
| **default** | P2 | 20 | Notifications, analytics events |
| **low** | P3 | 5 | Reports, cleanup, batch exports |
| **scheduled** | N/A | 3 | Cron-like scheduled tasks |
| **dead-letter** | N/A | 1 | Failed tasks investigation |

## Retry Strategy

| Retry Policy | Configuration | Use Case |
|--------------|---------------|----------|
| **Exponential Backoff** | base=1s, max=1h, multiplier=2 | API calls, external services |
| **Fixed Interval** | interval=30s, max_retries=5 | Database operations |
| **No Retry** | max_retries=0 | Idempotent operations |

## Dead Letter Queue (DLQ) Handling

| Ã‰tape | Action |
|-------|--------|
| 1 | Task fails aprÃ¨s max retries |
| 2 | Task moved to DLQ avec metadata (reason, stack trace, attempts) |
| 3 | Alert Slack (P3) |
| 4 | On-call investigate |
| 5 | Options: Fix â†’ Replay, Manual resolution, Archive |

## Scheduled Jobs (CronJobs)

| Job | Schedule | Service | Description |
|-----|----------|---------|-------------|
| **balance-reconciliation** | `0 2 * * *` | svc-wallet | Daily balance verification |
| **expired-giftcards** | `0 0 * * *` | svc-giftcard | Mark expired cards |
| **analytics-rollup** | `0 */6 * * *` | svc-analytics | 6-hourly aggregation |
| **log-cleanup** | `0 3 * * 0` | platform | Weekly log rotation |
| **backup-verification** | `0 4 * * *` | platform | Daily backup integrity check |
| **compliance-report** | `0 6 1 * *` | platform | Monthly compliance export |

## Task Queue Monitoring

| Metric | Seuil alerte | Action |
|--------|--------------|--------|
| **Queue Depth** | > 1000 tasks | Scale workers |
| **Processing Time P95** | > 30s | Optimize task, check resources |
| **Failure Rate** | > 5% | Investigate DLQ, check dependencies |
| **DLQ Size** | > 10 tasks | Immediate investigation |
| **Worker Availability** | < 50% | Check pod health, scale up |

---

*Document maintenu par : Platform Team + Backend Team*  
*DerniÃ¨re mise Ã  jour : Janvier 2026*
